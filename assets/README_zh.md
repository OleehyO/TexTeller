<div align="center">
<h1><img src="./fire.svg" width=30, height=30> 
ğšƒğšğš¡ğšƒğšğš•ğš•ğšğš› <img src="./fire.svg" width=30, height=30> </h1>

<p align="center">
<a href="../README.md">English</a> | ä¸­æ–‡ç‰ˆæœ¬
</p>

<p align="center">
  <img src="./web_demo.gif" alt="TexTeller_demo" width=800>
</p>

</div>

TexTelleræ˜¯ä¸€ä¸ªåŸºäºViTçš„ç«¯åˆ°ç«¯å…¬å¼è¯†åˆ«æ¨¡å‹ï¼Œå¯ä»¥æŠŠå›¾ç‰‡è½¬æ¢ä¸ºå¯¹åº”çš„latexå…¬å¼

TexTellerç”¨äº†550Kçš„å›¾ç‰‡-å…¬å¼å¯¹è¿›è¡Œè®­ç»ƒ(æ•°æ®é›†å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/datasets/OleehyO/latex-formulas)è·å–)ï¼Œç›¸æ¯”äº[LaTeX-OCR](https://github.com/lukas-blecher/LaTeX-OCR)(ä½¿ç”¨äº†ä¸€ä¸ª100Kçš„æ•°æ®é›†)ï¼ŒTexTellerå…·æœ‰**æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ä»¥åŠ**æ›´é«˜çš„å‡†ç¡®ç‡**ï¼Œå¯ä»¥è¦†ç›–å¤§éƒ¨åˆ†çš„ä½¿ç”¨åœºæ™¯(**æ‰«æå›¾ç‰‡ï¼Œæ‰‹å†™å…¬å¼é™¤å¤–**)ã€‚

> æˆ‘ä»¬é©¬ä¸Šå°±ä¼šå‘å¸ƒä¸€ä¸ªä½¿ç”¨5.5Mæ•°æ®é›†è¿›è¡Œè®­ç»ƒçš„TexTeller checkpoint

## å‰ç½®æ¡ä»¶

python=3.10

pytorch

> æ³¨æ„: åªæœ‰CUDAç‰ˆæœ¬>= 12.0è¢«å®Œå…¨æµ‹è¯•è¿‡ï¼Œæ‰€ä»¥æœ€å¥½ä½¿ç”¨>= 12.0çš„CUDAç‰ˆæœ¬

## Getting Started

1. å…‹éš†æœ¬ä»“åº“:

    ```bash
    git clone https://github.com/OleehyO/TexTeller
    ```

2. [å®‰è£…pytorch](https://pytorch.org/get-started/locally/#start-locally)åï¼Œå†å®‰è£…æœ¬é¡¹ç›®çš„ä¾èµ–åŒ…:

    ```bash
    pip install -r requirements.txt
    ```

3. è¿›å…¥`TexTeller/src`ç›®å½•ï¼Œåœ¨ç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨ç†:

    ```bash
    python inference.py -img "/path/to/image.{jpg,png}" 
    # use -cuda option to enable GPU inference
    #+e.g. python inference.py -img "./img.jpg" -cuda
    ```

    > ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ä¼šåœ¨hugging faceä¸Šä¸‹è½½æ‰€éœ€è¦çš„checkpoints

## FAQï¼šæ— æ³•è¿æ¥åˆ°Hugging Face

é»˜è®¤æƒ…å†µä¸‹ï¼Œä¼šåœ¨Hugging Faceä¸­ä¸‹è½½æ¨¡å‹æƒé‡ï¼Œ**å¦‚æœä½ çš„è¿œç«¯æœåŠ¡å™¨æ— æ³•è¿æ¥åˆ°Hugging Face**ï¼Œä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡ŒåŠ è½½ï¼š

1. å®‰è£…huggingface hubåŒ…

    ```bash
    pip install -U "huggingface_hub[cli]"
    ```

2. åœ¨èƒ½è¿æ¥Hugging Faceçš„æœºå™¨ä¸Šä¸‹è½½æ¨¡å‹æƒé‡:

    ```bash
    huggingface-cli download OleehyO/TexTeller --include "*.json" "*.bin" "*.txt" --repo-type model --local-dir "your/dir/path"
    ```

3. æŠŠåŒ…å«æƒé‡çš„ç›®å½•ä¸Šä¼ è¿œç«¯æœåŠ¡å™¨ï¼Œç„¶åæŠŠ`TexTeller/src/models/ocr_model/model/TexTeller.py`ä¸­çš„`REPO_NAME = 'OleehyO/TexTeller'`ä¿®æ”¹ä¸º`REPO_NAME = 'your/dir/path'`

å¦‚æœä½ è¿˜æƒ³åœ¨è®­ç»ƒæ¨¡å‹æ—¶å¼€å¯evaluateï¼Œä½ éœ€è¦æå‰ä¸‹è½½metricè„šæœ¬å¹¶ä¸Šä¼ è¿œç«¯æœåŠ¡å™¨ï¼š

1. åœ¨èƒ½è¿æ¥Hugging Faceçš„æœºå™¨ä¸Šä¸‹è½½metricè„šæœ¬

    ```bash
    huggingface-cli download evaluate-metric/google_bleu --repo-type space --local-dir "your/dir/path"
    ```

2. æŠŠè¿™ä¸ªç›®å½•ä¸Šä¼ è¿œç«¯æœåŠ¡å™¨ï¼Œå¹¶åœ¨`TexTeller/src/models/ocr_model/utils/metrics.py`ä¸­æŠŠ`evaluate.load('google_bleu')`æ”¹ä¸º`evaluate.load('your/dir/path/google_bleu.py')`

## Web Demo

è¦æƒ³å¯åŠ¨web demoï¼Œä½ éœ€è¦å…ˆè¿›å…¥ `TexTeller/src` ç›®å½•ï¼Œç„¶åè¿è¡Œä»¥ä¸‹å‘½ä»¤

```bash
./start_web.sh
```

ç„¶ååœ¨æµè§ˆå™¨é‡Œè¾“å…¥`http://localhost:8501`å°±å¯ä»¥çœ‹åˆ°web demo

> ä½ å¯ä»¥æ”¹å˜`start_web.sh`çš„é»˜è®¤é…ç½®ï¼Œ ä¾‹å¦‚ä½¿ç”¨GPUè¿›è¡Œæ¨ç†(e.g. `USE_CUDA=True`) æˆ–è€…å¢åŠ beamsçš„æ•°é‡(e.g. `NUM_BEAM=3`)æ¥è·å¾—æ›´é«˜çš„ç²¾ç¡®åº¦

## API

æˆ‘ä»¬ä½¿ç”¨[ray serve](https://github.com/ray-project/ray)æ¥å¯¹å¤–æä¾›ä¸€ä¸ªTexTellerçš„APIæ¥å£ï¼Œé€šè¿‡ä½¿ç”¨è¿™ä¸ªæ¥å£ï¼Œä½ å¯ä»¥æŠŠTexTelleræ•´åˆåˆ°è‡ªå·±çš„é¡¹ç›®é‡Œã€‚è¦æƒ³å¯åŠ¨serverï¼Œä½ éœ€è¦å…ˆè¿›å…¥`TexTeller/src`ç›®å½•ç„¶åè¿è¡Œä»¥ä¸‹å‘½ä»¤:

```bash
python server.py  # default settings
```

ä½ å¯ä»¥ç»™`server.py`ä¼ é€’ä»¥ä¸‹å‚æ•°æ¥æ”¹å˜serverçš„æ¨ç†è®¾ç½®(e.g. `python server.py --use_gpu` æ¥å¯åŠ¨GPUæ¨ç†):

| Argument | Description |
| --- | --- |
| `-ckpt` | Path to the checkpoint file to load, default is TexTeller pretrained model. |
| `-tknz` | Path to the tokenizer, default is TexTeller tokenizer. |
| `-port` | Port number to run the server on, *default is 8000*. |
| `--use_gpu` | Whether to use GPU for inference. |
| `--num_beams` | Number of beams to use for beam search decoding, *default is 1*. |
| `--num_replicas` | Number of replicas to run the server on, *default is 1*. You can use this to get higher throughput. |
| `--ncpu_per_replica` | Number of CPU cores to use per replica, *default is 1*. |
| `--ngpu_per_replica` | Number of GPUs to use per replica, *default is 1*. You can set this to 0~1 to run multiple replicas on a single GPU(if --num_replicas 2, --ngpu_per_replica 0.7, then 2 gpus are required) |

> ä¸€ä¸ªå®¢æˆ·ç«¯demoå¯ä»¥åœ¨`TexTeller/client/demo.py`æ‰¾åˆ°ï¼Œä½ å¯ä»¥å‚è€ƒ`demo.py`æ¥ç»™serverå‘é€è¯·æ±‚

## Training

### Dataset

æˆ‘ä»¬åœ¨`TexTeller/src/models/ocr_model/train/dataset`ç›®å½•ä¸­æä¾›äº†ä¸€ä¸ªæ•°æ®é›†çš„ä¾‹å­ï¼Œä½ å¯ä»¥æŠŠè‡ªå·±çš„å›¾ç‰‡æ”¾åœ¨`images`ç›®å½•ç„¶ååœ¨`formulas.jsonl`ä¸­ä¸ºæ¯å¼ å›¾ç‰‡æ ‡æ³¨å¯¹åº”çš„å…¬å¼ã€‚

å‡†å¤‡å¥½æ•°æ®é›†åï¼Œä½ éœ€è¦åœ¨`.../dataset/loader.py`ä¸­æŠŠ **`DIR_URL`å˜é‡æ”¹æˆä½ è‡ªå·±æ•°æ®é›†çš„è·¯å¾„**

### Retrain the tokenizer

å¦‚æœä½ ä½¿ç”¨äº†ä¸ä¸€æ ·çš„æ•°æ®é›†ï¼Œä½ å¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒtokenizeræ¥å¾—åˆ°ä¸€ä¸ªä¸ä¸€æ ·çš„å­—å…¸ã€‚é…ç½®å¥½æ•°æ®é›†åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ¥è®­ç»ƒè‡ªå·±çš„tokenizerï¼š

1. åœ¨`TexTeller/src/models/tokenizer/train.py`ä¸­ï¼Œä¿®æ”¹`new_tokenizer.save_pretrained('./your_dir_name')`ä¸ºä½ è‡ªå®šä¹‰çš„è¾“å‡ºç›®å½•
    > å¦‚æœè¦ç”¨ä¸€ä¸ªä¸ä¸€æ ·å¤§å°çš„å­—å…¸(é»˜è®¤1Wä¸ªtoken)ï¼Œä½ éœ€è¦åœ¨ `TexTeller/src/models/globals.py`ä¸­ä¿®æ”¹`VOCAB_SIZE`å˜é‡

2. **åœ¨ `TexTeller/src` ç›®å½•ä¸‹**è¿è¡Œä»¥ä¸‹å‘½ä»¤:

    ```bash
    python -m models.tokenizer.train
    ```

### Train the model

è¦æƒ³è®­ç»ƒæ¨¡å‹, ä½ éœ€è¦åœ¨`TexTeller/src`ç›®å½•ä¸‹è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
python -m models.ocr_model.train.train
```

ä½ å¯ä»¥åœ¨`TexTeller/src/models/ocr_model/train/train.py`ä¸­è®¾ç½®è‡ªå·±çš„tokenizerå’Œcheckpointè·¯å¾„ï¼ˆè¯·å‚è€ƒ`train.py`ï¼‰ã€‚å¦‚æœä½ ä½¿ç”¨äº†ä¸TexTellerä¸€æ ·çš„æ¶æ„å’Œç›¸åŒçš„å­—å…¸ï¼Œä½ è¿˜å¯ä»¥ç”¨è‡ªå·±çš„æ•°æ®é›†æ¥å¾®è°ƒTexTellerçš„é»˜è®¤æƒé‡ã€‚

åœ¨`TexTeller/src/globals.py`å’Œ`TexTeller/src/models/ocr_model/train/train_args.py`ä¸­ï¼Œä½ å¯ä»¥æ”¹å˜æ¨¡å‹çš„æ¶æ„ä»¥åŠè®­ç»ƒçš„è¶…å‚æ•°ã€‚

> æˆ‘ä»¬çš„è®­ç»ƒè„šæœ¬ä½¿ç”¨äº†[Hugging Face Transformers](https://github.com/huggingface/transformers)åº“, æ‰€ä»¥ä½ å¯ä»¥å‚è€ƒä»–ä»¬æä¾›çš„[æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.32.1/main_classes/trainer#transformers.TrainingArguments)æ¥è·å–æ›´å¤šè®­ç»ƒå‚æ•°çš„ç»†èŠ‚ä»¥åŠé…ç½®ã€‚

## To-Do

- [ ] ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†æ¥è®­ç»ƒæ¨¡å‹(5.5Mæ ·æœ¬ï¼Œå³å°†å‘å¸ƒ)

- [ ] æ¨ç†åŠ é€Ÿ

- [ ] ...

## Acknowledgements

Thanks to [LaTeX-OCR](https://github.com/lukas-blecher/LaTeX-OCR) which has brought me a lot of inspiration, and [im2latex-100K](https://zenodo.org/records/56198#.V2px0jXT6eA) which enriches our dataset.